{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/NLP /NLP Final Project/plots.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(cell):\n",
    "    if isinstance(cell, str):\n",
    "        cell = cell.lower()\n",
    "        cell = ''.join(char if char not in punctuation else ' ' for char in cell)\n",
    "        words = cell.split()\n",
    "        filtered_words = [\n",
    "            lemmatizer.lemmatize(word) for word in words if word not in stop_words\n",
    "        ]\n",
    "        return \" \".join(filtered_words)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-cb83073aea89>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(process_text)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df = df.applymap(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "tfidf_matrix = tf.fit_transform(df['Plot Summary'])\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "n = len(df)\n",
    "feedback_matrix = np.random.randint(-5, 6, size=(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_similarity_with_feedback(sim_matrix, feedback_matrix, boost=0.1, penalty=0.1):\n",
    "    adjusted_sim_matrix = sim_matrix.copy()\n",
    "    for i in range(len(feedback_matrix)):\n",
    "        for j in range(len(feedback_matrix)):\n",
    "            if feedback_matrix[i, j] > 0:\n",
    "                adjusted_sim_matrix[i, j] += boost * feedback_matrix[i, j]\n",
    "            elif feedback_matrix[i, j] < 0:\n",
    "                adjusted_sim_matrix[i, j] += penalty * feedback_matrix[i, j]\n",
    "                adjusted_sim_matrix[i, j] = max(0, adjusted_sim_matrix[i, j])\n",
    "    return adjusted_sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_matrix_adjusted = adjust_similarity_with_feedback(cosine_sim_matrix, feedback_matrix)\n",
    "\n",
    "cosine_sim_df_adjusted = pd.DataFrame(cosine_sim_matrix_adjusted, index=df['Code'], columns=df['Code'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_recommendations(sim_matrix, item_codes):\n",
    "    top_5_recommendations = {}\n",
    "    for idx, item in enumerate(item_codes):\n",
    "        sim_scores = list(enumerate(sim_matrix[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        top_5 = [item_codes[i] for i, score in sim_scores[1:6]]\n",
    "        top_5_recommendations[item] = top_5\n",
    "\n",
    "    return top_5_recommendations\n",
    "item_codes = df['Code'].tolist()\n",
    "\n",
    "\n",
    "top_5_recs = get_top_5_recommendations(cosine_sim_matrix_adjusted, item_codes)\n",
    "\n",
    "\n",
    "for item, recommendations in top_5_recs.items():\n",
    "    print(f\"Top 5 recommendations for {item}: {recommendations}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
